{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import string\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(f):\n",
    "    for l in gzip.open(f):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39239\n"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "valid_data = []\n",
    "data = []\n",
    "userCatCounts = defaultdict(list)\n",
    "\n",
    "words_cat = defaultdict(list)\n",
    "for l in readGz('train.json.gz'):\n",
    "    user,category,item,review = l['reviewerID'],l['categoryID'],l['itemID'],l['reviewText']\n",
    "    data.append((user, category, item, review))\n",
    "    if user not in userCatCounts:\n",
    "        userCatCounts[user] = [0, 0, 0, 0, 0]\n",
    "    if category == 0:\n",
    "        words_cat[0].append(review)\n",
    "        userCatCounts[user][0] += 1\n",
    "    elif category == 1:\n",
    "        words_cat[1].append(review)\n",
    "        userCatCounts[user][1] += 1\n",
    "    elif category == 2:\n",
    "        words_cat[2].append(review)\n",
    "        userCatCounts[user][2] += 1\n",
    "    elif category == 3:\n",
    "        words_cat[3].append(review)\n",
    "        userCatCounts[user][3] += 1\n",
    "    elif category == 4:\n",
    "        words_cat[4].append(review)\n",
    "        userCatCounts[user][4] += 1\n",
    "train_data = data[:155000]\n",
    "valid_data = data[155000:]\n",
    "print(len(userCatCounts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess the data and find the counts for each word.\n",
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in train_data:\n",
    "    r = ''.join([c for c in d[3].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        wordCount[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopWords(data):\n",
    "    #get the 750 most common words\n",
    "    common = set(['a', 'and', 'but', 'from', 'to', 'on', 'for', 'the', 'of'])\n",
    "    counts = [(data[w], w) for w in data]\n",
    "    counts.sort()\n",
    "    counts.reverse()\n",
    "    words = [x for x in counts[:1000] if not x in common]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = getTopWords(wordCount)\n",
    "total = 0\n",
    "for tup in words:\n",
    "    total += tup[0]\n",
    "freqWordsTotal = {}\n",
    "for x in words:\n",
    "    freqWordsTotal[x[1]] = x[0] / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "catDataDict = defaultdict(list)\n",
    "for tup in train_data:\n",
    "    if tup[1] == 0:\n",
    "        catDataDict[0].append(tup)\n",
    "    elif tup[1] == 1:\n",
    "        catDataDict[1].append(tup)\n",
    "    elif tup[1] == 2:\n",
    "        catDataDict[2].append(tup)\n",
    "    elif tup[1] == 3:\n",
    "        catDataDict[3].append(tup)\n",
    "    elif tup[1] == 4:\n",
    "        catDataDict[4].append(tup)\n",
    "        \n",
    "        \n",
    "\n",
    "def computeFreqForCat(data):\n",
    "    wc = defaultdict(int)\n",
    "    punctuation = set(string.punctuation)\n",
    "    for tup in data:\n",
    "        r = ''.join([c for c in tup[3].lower() if not c in punctuation])\n",
    "        for w in r.split():\n",
    "            wc[w] += 1\n",
    "    return wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "catFreqs = defaultdict(dict)\n",
    "for i in range(5):\n",
    "    wc = computeFreqForCat(catDataDict[i])\n",
    "    total = 0\n",
    "    new_dict = {}\n",
    "    for key, val in list(freqWordsTotal.items()):\n",
    "        total += wc[key]\n",
    "    for key, val in list(freqWordsTotal.items()):\n",
    "        new_dict[key] = wc[key] / total\n",
    "    catFreqs[i] = new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dict ={}\n",
    "topWords = defaultdict(list)\n",
    "for i in range(5):\n",
    "    l = []\n",
    "    for key, val in list(freqWordsTotal.items()):\n",
    "        diff = catFreqs[i][key] - val\n",
    "        l.append((diff, key))\n",
    "    temp_dict[i] = l\n",
    "for i in range(5):\n",
    "    temp_dict[i].sort()\n",
    "    temp_dict[i].reverse()\n",
    "    for x in range(700):\n",
    "        topWords[i].append(temp_dict[i][x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalWords = []\n",
    "for val in topWords.values():\n",
    "    finalWords.extend(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3499"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(finalWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155000 155000\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "for d in train_data:\n",
    "    y.append(d[1])\n",
    "    feat = [x[1] in d[3] for x in set(finalWords)]\n",
    "    feat.extend(userCatCounts[d[0]])\n",
    "    X.append(feat)\n",
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000 45000\n"
     ]
    }
   ],
   "source": [
    "X_valid = []\n",
    "y_valid = []\n",
    "for d in valid_data:\n",
    "    y_valid.append(d[1])\n",
    "    feat = [x[1] in d[3] for x in set(finalWords)]\n",
    "    feat.extend(userCatCounts[d[0]])\n",
    "    X_valid.append(feat)\n",
    "print(len(X_valid), len(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.LinearSVC(C=10.0, multi_class='ovr', dual=False)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9097677419354838"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9052"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Category.txt\", 'w')\n",
    "predictions.write(\"reviewerID-reviewHash,category\\n\")\n",
    "for l in readGz(\"test_Category.json.gz\"):\n",
    "    x_test = []\n",
    "    words = l['reviewText'].lower()\n",
    "    feat = [x[1] in words for x in set(finalWords)]\n",
    "    counts = userCatCounts[l['reviewerID']]\n",
    "    if len(counts) == 0:\n",
    "        counts = [0, 0, 0, 0, 0]\n",
    "    feat.extend(counts)\n",
    "    x_test.append(feat)\n",
    "    pred = clf.predict(x_test)\n",
    "    predictions.write(l['reviewerID'] + '-' + l['reviewHash'] + \",\" + str(pred[0]) + \"\\n\")\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PurchasePredictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data2 = []\n",
    "valid_data2 = []\n",
    "users = []\n",
    "items = []\n",
    "userCategories = defaultdict(list)\n",
    "itemCategories = defaultdict(list)\n",
    "user_item_dict = defaultdict(set)\n",
    "i = 0\n",
    "for l in readGz('train.json.gz'):\n",
    "    user,category,item,rating,helpful,summary  = l['reviewerID'],l['categoryID'],l['itemID'], l['rating'], l['helpful'], l['summary']\n",
    "    items.append(item)\n",
    "    users.append(user)\n",
    "    user_item_dict[user].add(item)\n",
    "    if i < 100000:\n",
    "        userCategories[user].append((category, rating, helpful, summary, item))\n",
    "        itemCategories[item].append((category, rating, helpful, summary, item))\n",
    "        train_data2.append((user, item))\n",
    "    else:\n",
    "        valid_data2.append((user, item))\n",
    "    i += 1\n",
    "user_set = set(users)\n",
    "item_set = set(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pick negative samples for the valid data\n",
    "import random\n",
    "num = 0\n",
    "while num < 100000:\n",
    "    u = random.sample(user_set, 1)\n",
    "    i = random.sample(item_set, 1)\n",
    "    if i[0] not in user_item_dict[u[0]]:\n",
    "        train_data2.append((u[0], i[0], -1))\n",
    "        num += 1\n",
    "        \n",
    "num = 0\n",
    "while num < 100000:\n",
    "    u = random.sample(user_set, 1)\n",
    "    i = random.sample(item_set, 1)\n",
    "    if i[0] not in user_item_dict[u[0]]:\n",
    "        valid_data2.append((u[0], i[0], -1))\n",
    "        num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrain the baseline on just the new train data\n",
    "businessCount = defaultdict(int)\n",
    "userCount = defaultdict(int)\n",
    "totalPurchases = 0\n",
    "\n",
    "#item pop:\n",
    "for tup in train_data2:\n",
    "    item = tup[1]\n",
    "    user = tup[0]\n",
    "    businessCount[item] += 1\n",
    "    userCount[user] += 1\n",
    "    totalPurchases += 1\n",
    "\n",
    "mostPopular = [(businessCount[x], x) for x in businessCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return1.add(i)\n",
    "    if count > totalPurchases/1.8: break\n",
    "        \n",
    "mostPopular = [(userCount[x], x) for x in userCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "return2 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return2.add(i)\n",
    "    if count > totalPurchases/1.8: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "itemAvg = {}\n",
    "total = 0\n",
    "#find the popularity of the items\n",
    "for key, val in list(itemCategories.items()):\n",
    "    #key is the item and val is the data tuple\n",
    "    total += len(val)\n",
    "for key, val in list(itemCategories.items()):\n",
    "    t = 0\n",
    "    for tup in val:\n",
    "        t += tup[1]\n",
    "    itemAvg[key] = t / len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "userAvg = {}\n",
    "for key, val in list(userCategories.items()):\n",
    "    t = 0\n",
    "    for tup in val:\n",
    "        t += tup[1]\n",
    "    userAvg[key] = t / len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "userCatCounts = defaultdict(dict)\n",
    "for key, val in list(userCategories.items()):\n",
    "    for tup in val:\n",
    "        if tup[0] in userCatCounts[key]:\n",
    "            userCatCounts[key][tup[0]] += 1\n",
    "        else:\n",
    "            userCatCounts[key][tup[0]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# itemCounts = defaultdict(int)\n",
    "# for key, val in list(userCategories.items()):\n",
    "#     for i in range(len(val)):\n",
    "#         for j in range(len(val)):\n",
    "#             if i == j: continue\n",
    "#             itemCounts[(val[i][4], val[j][4])] += 1\n",
    "#             itemCounts[(val[j][4], val[i][4])] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "287782"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(itemCounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n"
     ]
    }
   ],
   "source": [
    "y = []\n",
    "for i in range(100000):\n",
    "    y.append(1)\n",
    "for i in range(100000):\n",
    "    y.append(0)\n",
    "X = []\n",
    "for data in train_data2:\n",
    "    item, user = data[1], data[0]\n",
    "    feat = []\n",
    "    if item not in itemAvg or user not in userCategories:\n",
    "        feat = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "        X.append(feat)\n",
    "        continue\n",
    "    cat = itemCategories[item][0][0]\n",
    "    feat.append(cat)\n",
    "    \n",
    "    avg = itemAvg[item]\n",
    "    feat.append(avg)\n",
    "    \n",
    "    ua = userAvg[user]\n",
    "    feat.append(ua)\n",
    "    \n",
    "    feat.append(item in return1)\n",
    "    feat.append(user in return2)\n",
    "    for i in range(5):\n",
    "        if i in userCatCounts[user]:\n",
    "            cnt = userCatCounts[user][i]\n",
    "            feat.append(cnt)\n",
    "        else:\n",
    "            feat.append(0)\n",
    "    X.append(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000 200000 200000 200000\n"
     ]
    }
   ],
   "source": [
    "y_valid = []\n",
    "for i in range(100000):\n",
    "    y_valid.append(1)\n",
    "for i in range(100000):\n",
    "    y_valid.append(0)\n",
    "X_valid = []\n",
    "for data in valid_data2:\n",
    "    item, user = data[1], data[0]\n",
    "    feat = []\n",
    "    if item not in itemAvg or user not in userCategories:\n",
    "        feat = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "        X_valid.append(feat)\n",
    "        continue\n",
    "    feat.append(tc)\n",
    "    cat = itemCategories[item][0][0]\n",
    "    \n",
    "    feat.append(cat)\n",
    "    \n",
    "    avg = itemAvg[item]\n",
    "    feat.append(avg)\n",
    "    \n",
    "    ua = userAvg[user]\n",
    "    feat.append(ua)\n",
    "    \n",
    "    feat.append(item in return1)\n",
    "    feat.append(user in return2)\n",
    "    for i in range(5):\n",
    "        if i in userCatCounts[user]:\n",
    "            cnt = userCatCounts[user][i]\n",
    "            feat.append(cnt)\n",
    "        else:\n",
    "            feat.append(0)\n",
    "    X_valid.append(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.LinearSVC(C=10.0, dual=False)\n",
    "clf.fit(X, y)\n",
    "clf.score(X, y)\n",
    "clf.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.956625"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.516465"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Purchase.txt\", 'w')\n",
    "for l in open(\"pairs_Purchase.txt\"):\n",
    "    if l.startswith(\"reviewerID\"):\n",
    "        #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    user,item = l.strip().split('-')\n",
    "    \n",
    "    X_test = []\n",
    "    feat = [1]\n",
    "    if item not in itemAvg or user not in userCategories:\n",
    "        feat = [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "        X_test.append(feat)\n",
    "    else:\n",
    "        cat = itemCategories[item][0][0]\n",
    "\n",
    "        feat.append(cat)\n",
    "\n",
    "        avg = itemAvg[item]\n",
    "        feat.append(avg)\n",
    "\n",
    "        ua = userAvg[user]\n",
    "        feat.append(ua)\n",
    "\n",
    "        feat.append(item in return1)\n",
    "        feat.append(user in return2)\n",
    "        for i in range(5):\n",
    "            if i in userCatCounts[user]:\n",
    "                cnt = userCatCounts[user][i]\n",
    "                feat.append(cnt)\n",
    "            else:\n",
    "                feat.append(0)\n",
    "        X_test.append(feat)\n",
    "    pred = clf.predict(X_test)\n",
    "    predictions.write(user + '-' + item + \",\"+str(pred[0])+\"\\n\")\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
